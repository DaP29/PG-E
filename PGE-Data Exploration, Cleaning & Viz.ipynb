{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf3ccea",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Load Data](#section-1)\n",
    "* [Data Exploration & Cleaning](#section-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ca00e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06feacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951a8f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         df_list\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Concatenate all dataframes in the list into a single dataframe\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m df_years \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:404\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    401\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#Combining all the years together \n",
    "# data came from here - https://pge-energydatarequest.com/public_datasets/download?type=electric&file=PGE_2021_Q4_ElectricUsageByZip.zip\n",
    "# Create an empty list to store the dataframes\n",
    "current_dir = os.getcwd()\n",
    "df_list = []\n",
    "\n",
    "# Loop through each CSV file in the directory\n",
    "for filename in os.listdir(current_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file and append it to the list of dataframes\n",
    "        file_path = os.path.join(current_dir, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        #df['Quarter']=filename[9:11]\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "df_years = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41cbcc",
   "metadata": {},
   "source": [
    "# Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8289baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74185a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_years.info() \n",
    "# some columns like total customers are not integer or float types we'll need to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['totalcustomers']=df_years['totalcustomers'].str.replace(',','')\n",
    "df_years['totalkwh']=df_years['totalkwh'].str.replace(',','')\n",
    "df_years['averagekwh']=df_years['averagekwh'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['totalcustomers']=df_years['totalcustomers'].astype(int)\n",
    "df_years['totalkwh']=df_years['totalkwh'].astype(float)\n",
    "df_years['averagekwh']=df_years['averagekwh'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff47fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_years['combined'].value_counts(normalize=True)*100 # 65% of our data belongs to combines zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.duplicated().any() #determine duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc377c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.duplicated().sum() # we have 14863 duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[df_years.duplicated(keep=False)].sort_values(by=['zipcode','month','year']) # lets see these duplicates ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94614a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years=df_years.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78604e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['customerclass'].value_counts() # we have 4 classess of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea654a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets randomly check data consistency \n",
    "df_years[(df_years['zipcode']==94538) & (df_years['year']==2014)]['month'].value_counts()\n",
    "# we see that in 2014 we have 6 observations per month which is not what we expected \n",
    "# since we only have 4 types of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a263291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets look closer\n",
    "df_years[(df_years['zipcode']==94538) & (df_years['year']==2014)].sort_values(by=['customerclass','combined','month'])\n",
    "# we see that for some zipcodes some months are repeated but with different number of total customers\n",
    "# since we don't expect one zipcode to appear in the data several times per month \n",
    "# we should drop these duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[df_years.duplicated(subset=['zipcode', 'combined','month','year','customerclass','totalcustomers'], keep=False)].sort_values(by=['zipcode','month','year'])\n",
    "# these are our near duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ad111",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_years[df_years.duplicated(subset=['zipcode', 'combined','month','year','customerclass','totalcustomers'])])\n",
    "# we have 1520 such near duplicates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a63e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years=df_years.drop_duplicates(subset=['zipcode', 'combined','month','year','customerclass','totalcustomers'], keep='first')\n",
    "# lets keep the first occurence \n",
    "#later we can play with what happens if we keep the secon occurence\n",
    "# or create a measure which keeps the average of totalkwh and averagekwh  across all occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac16cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_years[(df_years['totalcustomers']==0) & (df_years['totalkwh']==0)& (df_years['averagekwh'].isnull())])\n",
    "# We also have some lines with all 0s in total customers, total kilowatt per hour and \n",
    "# missing average kilo watt per hour \n",
    "# this may indicate zip codes where PGE does not have any customers / no coverage \n",
    "# Since these observations does not add any info except the zipcodes themselves we could drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=(df_years['totalcustomers']==0) & (df_years['totalkwh']==0) & (df_years['averagekwh'].isnull())\n",
    "# filtering for these observations \n",
    "\n",
    "df_years=df_years[~mask] # excluding these observations from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3caf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_years[df_years.duplicated(subset=['zipcode', 'combined','month','year','customerclass'])])\n",
    "# lets check for other duplicates based on 'zipcode', 'combined','month','year','customerclass' only - we have 7777 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[df_years.duplicated(subset=['zipcode', 'combined','month','year','customerclass'],keep=False)].sort_values(by=['zipcode','month','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357da327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years=df_years.drop_duplicates(subset=['zipcode', 'combined','month','year','customerclass'], keep='first')\n",
    "# lets drop these duplicates too and keep the firts occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[(df_years['zipcode']==94538) & (df_years['year']==2014)].sort_values(by=['customerclass','combined','month'])\n",
    "# now the data looks good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[(df_years['customerclass']=='Elec- Commercial') & (df_years['year']==2013)& (df_years['zipcode']==94538) ]['month'].value_counts()\n",
    "# keep checking the data \n",
    "# this looks good as we have one observation for this zip code per commercial customer class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years[(df_years['customerclass']=='Elec- Residential') & (df_years['year']==2014)& (df_years['zipcode']==93203) ]['month'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['customerclass'].value_counts() # we still have 4 classess of customers but not so many industrial and agricultural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ebd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['customerclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f69568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years['zipcode'].nunique() # we have 827 zip codes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54853373",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pd.get_dummies(df_years['customerclass'], drop_first=True) # we create 3 dummies for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57edb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops categorical variables from the df\n",
    "#df_years = df_years.drop('customerclass', axis = 1) # lets not drop the initial avriable just for now\n",
    "\n",
    "# Adds the newly created dummy variables instead\n",
    "df_years = pd.concat([df_years, ohe], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d2b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine if there is missing values\n",
    "df_years.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb15b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d8138",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(customer_class, parameter):\n",
    "    df=df_years[df_years['customerclass']==customer_class]\n",
    "    unique_years = df['year'].unique()\n",
    "\n",
    "    # Set the seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Create a separate histogram for each year\n",
    "    for year in unique_years:\n",
    "        # Filter the DataFrame for the current year\n",
    "        df_year = df[df['year'] == year]\n",
    "\n",
    "        # Create a FacetGrid for the current year\n",
    "        g = sns.FacetGrid(df_year, row='customerclass', height=3, aspect=3,sharex=False, sharey=False)\n",
    "        g.map(sns.histplot, parameter, bins=200)\n",
    "\n",
    "        # Set axis labels\n",
    "        g.set_axis_labels(parameter, 'Count')\n",
    "\n",
    "        for ax in g.axes.flat: # setting x and y to intersect at 0\n",
    "            ax.set_xlim(left=0)\n",
    "            ax.set_ylim(bottom=0)\n",
    "        g.set_axis_labels(parameter, 'Count')\n",
    "\n",
    "        for ax, customer_class in zip(g.axes.flat, g.row_names):\n",
    "        # Extract part of the customer_class starting from index 6\n",
    "            customer_class = customer_class[6:]\n",
    "      \n",
    "        for ax, title in zip(g.axes.flat, g.row_names):\n",
    "            ax.set_title(f\"Distribution of {customer_class} customers {parameter}: {year} year\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69178d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def viz_med(parameter,year=None):\n",
    "    grouped_data = df_years.groupby(['year', 'customerclass'])[parameter].median().reset_index()\n",
    "    # Set the seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "    labels=['Residential', 'Commercial', 'Agricultural', 'Industrial']\n",
    "    color_palette = sns.color_palette(\"flare\", len(grouped_data['year'].unique()))\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax = sns.barplot(x='customerclass', y=parameter, hue='year', palette=color_palette,data=grouped_data,order=['Elec- Residential','Elec- Commercial','Elec- Agricultural',  'Elec- Industrial'])\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Customer Class')\n",
    "    plt.ylabel(f'Median Number of {parameter}')\n",
    "    plt.title(f'Annual Median Number of {parameter} per Customer Class')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_med(parameter,year=None):\n",
    "    if year: # if year is given\n",
    "        grouped_data = df_years[df_years['year'] == year].groupby(['year', 'customerclass'])[parameter].median().reset_index()\n",
    "        title = f'Median Number of {parameter} per Customer Class for {year}'\n",
    "    else:\n",
    "        grouped_data = df_years.groupby(['year', 'customerclass'])[parameter].median().reset_index()\n",
    "        title = f'Annual Median Number of {parameter} per Customer Class'\n",
    "    # Set the seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "    labels=['Residential', 'Commercial', 'Agricultural', 'Industrial']\n",
    "    color_palette = sns.color_palette(\"flare\", len(grouped_data['year'].unique()))\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax = sns.barplot(x='customerclass', y=parameter, hue='year', palette=color_palette,data=grouped_data,order=['Elec- Residential','Elec- Commercial','Elec- Agricultural',  'Elec- Industrial'])\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Customer Class')\n",
    "    plt.ylabel(f'Median Number of {parameter}')\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Residential','totalcustomers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Commercial','totalcustomers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63aecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Industrial','totalcustomers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Agricultural','totalcustomers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_med('totalcustomers',year=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Residential','totalkwh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6eed3",
   "metadata": {},
   "source": [
    "## Distribution of Monthly Average Consumption by years and customer classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Residential','averagekwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a314120",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Commercial','averagekwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1936f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz('Elec- Industrial','averagekwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_med('averagekwh') #  industrial customers consumer a lot of kwh thats why the scale is in 10**6 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets graph median average kilowatt hours consumption wihout industrial clients\n",
    "df_years_noind=df_years[df_years['customerclass']!='Elec- Industrial']\n",
    "grouped_data = df_years.groupby(['year', 'customerclass'])['averagekwh'].median().reset_index()\n",
    "\n",
    "# Set the seaborn style\n",
    "sns.set(style='whitegrid')\n",
    "labels=['Residential', 'Commercial', 'Agricultural']\n",
    "color_palette = sns.color_palette(\"flare\", len(grouped_data['year'].unique()))\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = sns.barplot(x='customerclass', y='averagekwh', hue='year', palette=color_palette,data=grouped_data,order=['Elec- Residential','Elec- Commercial','Elec- Agricultural'])\n",
    "\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Customer Class')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.title('Annual Median Average kwh consumption per Customer Class')\n",
    "\n",
    "plt.show()\n",
    "# we see that residential customers consumer quite similar amount of kwh every year\n",
    "# while there has been an increase in consumption in 2021 for Agricultural and Commercial Custoemrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e38f7",
   "metadata": {},
   "source": [
    "## Monthly and Yearly Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets explore if there is any seasonality in energy consumption \n",
    "# by plotting consumption over months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb692992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "grouped_data = df_years.groupby(['customerclass', 'month']).agg({'averagekwh': 'median'})\n",
    "# I use median as it's more robust to outliers as compared to average\n",
    "grouped_data = grouped_data.reset_index()\n",
    "\n",
    "# use all customer classes but industrial for which the consumption is very high and which we will plot separately\n",
    "customer_classes = ['Elec- Residential','Elec- Commercial','Elec- Agricultural']\n",
    "customer_class_labels = ['Residential Customers', 'Commercial Customers', 'Agricultural Customers']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Iterate over each unique customer class and plot a line\n",
    "for i,customer_class in enumerate(customer_classes):\n",
    "    # Select data for the current customer class\n",
    "    data = grouped_data[grouped_data['customerclass'] == customer_class]\n",
    "    \n",
    "    # Find the maximum average consumption (averagejwh) point in the data for the current customer class\n",
    "    highest_point = data[data['averagekwh'] == data['averagekwh'].max()]\n",
    "    \n",
    "    # Plot the line for the current customer class\n",
    "    ax.plot(data['month'], data['averagekwh'], label=customer_class_labels[i])\n",
    "    \n",
    "    # Plot a marker at the highest point\n",
    "    ax.scatter(highest_point['month'], highest_point['averagekwh'], marker='o', color='red')\n",
    "    \n",
    "    # Customize x-axis labels with month names\n",
    "    ax.set_xticks(data['month'])\n",
    "    ax.set_xticklabels([calendar.month_name[m] for m in data['month']], rotation=45)\n",
    "\n",
    "# Customize the plot labels and title\n",
    "ax.set_xlabel(\"Month\")\n",
    "#ax.set_ylabel(\"Median of Average Kilowatt per hour energy consumption\")\n",
    "ax.set_title(\"Monthly Energy Consumption, kWh per Customer Average (2013-2021)\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# looks like summer months - July & August are peak months "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a80fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting industrial customers\n",
    "grouped_data = df_years.groupby(['customerclass', 'month']).agg({'averagekwh': 'median'})\n",
    "# I use median as it's more robust to outliers as compared to average\n",
    "grouped_data = grouped_data.reset_index()\n",
    "\n",
    "# use all customer classes but industrial for which the consumption is very high and which we will plot separately\n",
    "customer_classes = ['Elec- Industrial']\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Select data for the current customer class\n",
    "data = grouped_data[grouped_data['customerclass'] == customer_class]\n",
    "# Find the maximum average consumption (averagejwh) point \n",
    "highest_point = data[data['averagekwh'] == data['averagekwh'].max()]\n",
    "ax.plot(data['month'], data['averagekwh'])\n",
    "   \n",
    "# Plot a marker at the highest point\n",
    "ax.scatter(highest_point['month'], highest_point['averagekwh'], marker='o', color='red')\n",
    "    \n",
    "# Customize x-axis labels with month names\n",
    "ax.set_xticks(data['month'])\n",
    "ax.set_xticklabels([calendar.month_name[m] for m in data['month']], rotation=45)\n",
    "\n",
    "# Customize the plot labels and title\n",
    "ax.set_xlabel(\"Month\")\n",
    "#ax.set_ylabel(\"Median of Average Kilowatt per hour energy consumption\")\n",
    "ax.set_title(\"Monthly Energy Consumption, kwh per Industrial Customer Average (2013-2021)\")\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# July is a peak month for industrial customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fe944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see how consumption changed over the years i.e. time-series trends\n",
    "\n",
    "import calendar\n",
    "\n",
    "grouped_data = df_years.groupby(['customerclass', 'year']).agg({'averagekwh': 'sum'})\n",
    "# I use median as it's more robust to outliers as compared to average\n",
    "grouped_data = grouped_data.reset_index()\n",
    "\n",
    "# use all customer classes but industrial for which the consumption is very high and which we will plot separately\n",
    "customer_classes = ['Elec- Residential','Elec- Commercial','Elec- Agricultural']\n",
    "customer_class_labels = ['Residential Customers', 'Commercial Customers', 'Agricultural Customers']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Iterate over each unique customer class and plot a line\n",
    "for i,customer_class in enumerate(customer_classes):\n",
    "    # Select data for the current customer class\n",
    "    data = grouped_data[grouped_data['customerclass'] == customer_class]\n",
    "    \n",
    "    # Find the maximum average consumption (averagejwh) point in the data for the current customer class\n",
    "    highest_point = data[data['averagekwh'] == data['averagekwh'].max()]\n",
    "    \n",
    "    # Plot the line for the current customer class\n",
    "    ax.plot(data['year'], data['averagekwh'], label=customer_class_labels[i])\n",
    "    \n",
    "    # Plot a marker at the highest point\n",
    "    ax.scatter(highest_point['year'], highest_point['averagekwh'], marker='o', color='red')\n",
    "    \n",
    "    # Customize the plot labels and title\n",
    "ax.set_xlabel(\"Year\")\n",
    "#ax.set_ylabel(\"Median of Average Kilowatt per hour energy consumption\")\n",
    "ax.set_title(\"Annual Energy Consumption, kWh per Customer Average (2013-2021)\")\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# Residential and Agricultural customers consumed the most energy in 2021 over the last 8 years \n",
    "# while it's the opposite for Commercial Clients who consumed the least amount of energy in 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see how consumption changed over the years for industrial customers\n",
    "\n",
    "grouped_data = df_years.groupby(['customerclass', 'year']).agg({'averagekwh': 'sum'})\n",
    "# I use median as it's more robust to outliers as compared to average\n",
    "grouped_data = grouped_data.reset_index()\n",
    "customer_classes = ['Elec- Industrial']\n",
    "customer_class_labels = ['Industrial Customers']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "data = grouped_data[grouped_data['customerclass'] == customer_class]\n",
    "    \n",
    "# Find the maximum average consumption (averagejwh) point \n",
    "highest_point = data[data['averagekwh'] == data['averagekwh'].max()]\n",
    "    \n",
    "ax.plot(data['year'], data['averagekwh'])\n",
    "    \n",
    "# Plot a marker at the highest point\n",
    "ax.scatter(highest_point['year'], highest_point['averagekwh'], marker='o', color='red')\n",
    "    \n",
    "# Customize the plot labels and title\n",
    "ax.set_xlabel(\"Year\")\n",
    "#ax.set_ylabel(\"Median of Average Kilowatt per hour energy consumption\")\n",
    "ax.set_title(\"Annual Energy Consumption, kWh per Industrial Customer Average (2013-2021)\")\n",
    "ax.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "# Residential and Agricultural customers consumed the most energy in 2021 over the last 9 years \n",
    "# while it's the opposite for Commercial Clients who consumed the least amount of energy in 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccad6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "224.973px",
    "width": "249.095px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
